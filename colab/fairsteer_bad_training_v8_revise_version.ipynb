{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup & Installation"
      ],
      "metadata": {
        "id": "_SpvF5yvJwr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Installing required packages...\\n\")\n",
        "\n",
        "!pip install -q transformers datasets torch accelerate huggingface_hub tqdm scikit-learn matplotlib seaborn pandas\n",
        "\n",
        "print(\" Installation complete!\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T11:21:47.042926Z",
          "iopub.execute_input": "2025-11-21T11:21:47.043599Z"
        },
        "id": "QQFegK3MJwr3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from huggingface_hub import HfApi, create_repo, login\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" BAD Classifier Training (IMPROVED & BALANCED)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "BEJmJtP0Jwr4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Improved Configuration"
      ],
      "metadata": {
        "id": "V3xOHnQOJwr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingConfig:\n",
        "\n",
        "\n",
        "    # Model\n",
        "    base_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "    max_length = 512\n",
        "\n",
        "    # Data\n",
        "    bbq_dataset_name = \"bitlabsdb/BBQ_dataset\"\n",
        "    bbq_target_loc_dataset = \"bitlabsdb/BBQ_Target_Loc_Dataset\"\n",
        "    num_bbq_samples = 58942\n",
        "    train_val_split = 0.8\n",
        "\n",
        "    # Sampling\n",
        "    use_balanced_sampling = True\n",
        "    target_samples_per_class = 25000\n",
        "    min_samples_per_class = 5000\n",
        "\n",
        "    SEED = 42\n",
        "    # Training Hyperparameters\n",
        "    batch_size = 128\n",
        "    num_epochs = 100\n",
        "    learning_rate = 5e-4\n",
        "    weight_decay = 1e-4\n",
        "    early_stopping_patience = 15\n",
        "    gradient_clip_norm = 1.0\n",
        "\n",
        "\n",
        "    # TinyLlama has 22 layers. We scan a wider range to find the geometric sweet spot.\n",
        "    candidate_layers_range = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
        "\n",
        "\n",
        "    dropout_rate = 0.05\n",
        "\n",
        "    # Labels\n",
        "    LABEL_BIASED = 0\n",
        "    LABEL_UNBIASED = 1\n",
        "\n",
        "    # HuggingFace\n",
        "    hf_repo_name = \"bitlabsdb/bad-classifier-tinyllama-fairsteer-v2\"\n",
        "    hf_private = False\n",
        "\n",
        "    # Local\n",
        "    local_save_dir = \"./bad_model_fairsteer_v2\"\n",
        "\n",
        "config = TrainingConfig()\n",
        "\n",
        "print(\"  FairSteer-Aligned Training Configuration (Updated):\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Base Model:         {config.base_model_name}\")\n",
        "print(f\"Splitting Strategy: Group-wise (prevents data leakage)\")\n",
        "print(f\"Feature Proc:       Standardization (Zero-mean, Unit-variance)\")\n",
        "print(f\"Expanded Layers:    {config.candidate_layers_range}\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "H2PMl-ztJwr5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model Definition"
      ],
      "metadata": {
        "id": "Ls1XfpmRJwr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BADClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Biased Activation Detection (BAD) Classifier - FairSteer Aligned\n",
        "\n",
        "    Architecture: Dropout -> Linear layer -> Sigmoid\n",
        "\n",
        "    Changes:\n",
        "    - Added Dropout (p=0.05 default) to prevent overfitting and 'lazy' feature selection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int, dropout_rate: float = 0.05):\n",
        "        super().__init__()\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        # 2. Linear Layer\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        # Xavier initialization for stable training\n",
        "        nn.init.xavier_uniform_(self.linear.weight)\n",
        "        nn.init.zeros_(self.linear.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: Dropout -> Linear -> Logits\n",
        "        \"\"\"\n",
        "        # Apply dropout first\n",
        "        x = self.dropout(x)\n",
        "        return self.linear(x)\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        \"\"\"\n",
        "        Get probability of being UNBIASED\n",
        "        Returns: p(y=1) where y=1 means UNBIASED\n",
        "        \"\"\"\n",
        "        logits = self.forward(x)\n",
        "        probs = torch.sigmoid(logits).squeeze(-1)\n",
        "        return probs\n",
        "\n",
        "    def detect_bias(self, x, threshold: float = 0.5):\n",
        "        \"\"\"\n",
        "        Detect biased activations using FairSteer threshold\n",
        "        \"\"\"\n",
        "        unbiased_prob = self.predict_proba(x)\n",
        "        is_biased = unbiased_prob < threshold\n",
        "        return is_biased, unbiased_prob\n",
        "\n",
        "print(\"‚úÖ BAD Classifier defined (Architecture: Dropout -> Linear + Sigmoid)\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "V_XXLS2SJwr5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Target Loc dataset to view columns and counting records"
      ],
      "metadata": {
        "id": "-JlY9RM2Jwr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    from datasets import load_dataset\n",
        "except ImportError:\n",
        "    !pip install -q datasets\n",
        "    from datasets import load_dataset\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. DATA LOADING\n",
        "# ---------------------------------------------------------\n",
        "print(\"=\"*80)\n",
        "print(\" üì• LOADING DATASET & PREPARING VISUALIZATIONS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    # Try normal loading first\n",
        "    print(\"Attempting standard load...\")\n",
        "    dataset = load_dataset(\"bitlabsdb/BBQ_Target_Loc_Dataset\")\n",
        "    df = dataset['train'].to_pandas()\n",
        "\n",
        "except Exception as e:\n",
        "    # If error (the 'missing' value issue), use streaming method\n",
        "    print(\"‚ö†Ô∏è Standard load failed (likely type error). Using streaming method...\")\n",
        "    dataset = load_dataset(\"bitlabsdb/BBQ_Target_Loc_Dataset\", split='train', streaming=True)\n",
        "\n",
        "    # Convert streaming dataset to pandas\n",
        "    data_list = []\n",
        "    for example in dataset:\n",
        "        data_list.append(example)\n",
        "\n",
        "    df = pd.DataFrame(data_list)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. CLEANING\n",
        "# ---------------------------------------------------------\n",
        "print(\"Cleaning data...\")\n",
        "# Fix 'missing' string values in numeric columns\n",
        "for col in ['label', 'target_loc', 'target_loc_word']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].replace('missing', pd.NA)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Filter out records where target_loc is N/A or empty\n",
        "if 'target_loc' in df.columns:\n",
        "    original_count = len(df)\n",
        "    df = df[df['target_loc'].notna()]\n",
        "    # Ensure target_loc is integer for cleaner plotting\n",
        "    df['target_loc'] = df['target_loc'].astype(int)\n",
        "    filtered_count = original_count - len(df)\n",
        "    print(f\"   üîß Filtered out {filtered_count:,} records with missing target_loc\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è Column 'target_loc' not found in dataset\")\n",
        "\n",
        "print(f\"‚úÖ Final dataset ready: {len(df):,} rows √ó {len(df.columns)} columns\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. VISUALIZATION\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nüìä Generating Distribution Plots...\")\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Determine layout based on available columns\n",
        "# We try to find 'category' and 'context_condition' if they exist\n",
        "has_category = 'category' in df.columns\n",
        "has_context = 'context_condition' in df.columns\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
        "\n",
        "# --- PLOT 1: Target Location Distribution (The most important check) ---\n",
        "if 'target_loc' in df.columns:\n",
        "    sns.countplot(x='target_loc', data=df, ax=axes[0, 0], palette=\"viridis\")\n",
        "    axes[0, 0].set_title('Distribution of Target Locations (0=A, 1=B, 2=C)', fontsize=13)\n",
        "    axes[0, 0].set_xlabel('Target Location')\n",
        "    axes[0, 0].set_ylabel('Count')\n",
        "    axes[0, 0].bar_label(axes[0, 0].containers[0])\n",
        "\n",
        "# --- PLOT 2: Category Distribution ---\n",
        "if has_category:\n",
        "    # Get top categories to prevent overcrowding if there are too many\n",
        "    top_cats = df['category'].value_counts().head(15)\n",
        "    sns.barplot(x=top_cats.values, y=top_cats.index, ax=axes[0, 1], palette=\"magma\")\n",
        "    axes[0, 1].set_title('Distribution by Category', fontsize=13)\n",
        "    axes[0, 1].set_xlabel('Count')\n",
        "else:\n",
        "    axes[0, 1].text(0.5, 0.5, 'Category column missing', ha='center', fontsize=12)\n",
        "\n",
        "# --- PLOT 3: Context Condition ---\n",
        "if has_context:\n",
        "    sns.countplot(x='context_condition', data=df, ax=axes[1, 0], palette=\"coolwarm\")\n",
        "    axes[1, 0].set_title('Context: Ambiguous vs Disambiguated', fontsize=13)\n",
        "    axes[1, 0].bar_label(axes[1, 0].containers[0])\n",
        "else:\n",
        "    axes[1, 0].text(0.5, 0.5, 'Context column missing', ha='center', fontsize=12)\n",
        "\n",
        "# --- PLOT 4: Heatmap (Category vs Target) or Label Distribution ---\n",
        "if has_category and 'target_loc' in df.columns:\n",
        "    # Check for bias: Do certain categories prefer certain answers?\n",
        "    cross_tab = pd.crosstab(df['category'], df['target_loc'])\n",
        "    sns.heatmap(cross_tab, annot=True, fmt='d', cmap=\"YlGnBu\", ax=axes[1, 1])\n",
        "    axes[1, 1].set_title('Heatmap: Category vs Target Location', fontsize=13)\n",
        "    axes[1, 1].set_ylabel('')\n",
        "elif 'label' in df.columns:\n",
        "    # Fallback: Plot the 'label' column if category missing\n",
        "    sns.histplot(df['label'].dropna(), ax=axes[1, 1], bins=10, kde=True)\n",
        "    axes[1, 1].set_title('Label Distribution', fontsize=13)\n",
        "else:\n",
        "    axes[1, 1].text(0.5, 0.5, 'Not enough data for correlation', ha='center', fontsize=12)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. PREVIEW\n",
        "# ---------------------------------------------------------\n",
        "print(\"=\"*80)\n",
        "print(\"TOP 20 ROWS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "display(df.head(5))\n",
        "\n",
        "print(f\"\\nüí° DataFrame 'df' ready with {len(df):,} records!\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "rxgrrlhpJwr6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Loading"
      ],
      "metadata": {
        "id": "sks_dWPjJwr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_merge_bbq_with_targetloc(config: TrainingConfig) -> pd.DataFrame:\n",
        "    \"\"\"Load BBQ dataset and merge with target_loc\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\" Loading BBQ Dataset with Target_Loc\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    # Load BBQ dataset\n",
        "    print(\"Loading BBQ dataset...\")\n",
        "    try:\n",
        "        bbq_dataset = load_dataset(config.bbq_dataset_name)\n",
        "        print(f\" Loaded BBQ: {config.bbq_dataset_name}\")\n",
        "    except:\n",
        "        bbq_dataset = load_dataset(\"nyu-mll/BBQ\")\n",
        "        print(f\" Loaded BBQ: nyu-mll/BBQ\")\n",
        "\n",
        "    # Load Target_Loc\n",
        "    print(\"\\nLoading Target_Loc dataset...\")\n",
        "    from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "    csv_path = hf_hub_download(\n",
        "        repo_id=config.bbq_target_loc_dataset,\n",
        "        filename=\"Untitled spreadsheet - additional_metadata.csv\",\n",
        "        repo_type=\"dataset\"\n",
        "    )\n",
        "\n",
        "    targetloc_df = pd.read_csv(csv_path, keep_default_na=False)\n",
        "    targetloc_df['target_loc'] = pd.to_numeric(targetloc_df['target_loc'], errors='coerce')\n",
        "\n",
        "    # Deduplicate\n",
        "    if targetloc_df['example_id'].duplicated().any():\n",
        "        targetloc_df = targetloc_df.drop_duplicates(subset=['example_id'], keep='first')\n",
        "\n",
        "    print(f\" Loaded Target_Loc\")\n",
        "\n",
        "    # Merge\n",
        "    bbq_df = pd.DataFrame(bbq_dataset['train'])\n",
        "    merged_df = pd.merge(\n",
        "        bbq_df,\n",
        "        targetloc_df[['example_id', 'target_loc']],\n",
        "        on='example_id',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # Clean\n",
        "    merged_df = merged_df[merged_df['target_loc'].notnull()]\n",
        "    merged_df = merged_df[merged_df['target_loc'].isin([0, 1, 2])]\n",
        "\n",
        "    if len(merged_df) > config.num_bbq_samples:\n",
        "        merged_df = merged_df.sample(n=config.num_bbq_samples, random_state=SEED)\n",
        "\n",
        "    print(f\"\\n Final BBQ dataset: {len(merged_df):,} rows\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# Load BBQ\n",
        "bbq_merged_df = load_and_merge_bbq_with_targetloc(config)\n",
        "display(bbq_merged_df.head(20))\n",
        "print(f\"Sample: {len(bbq_merged_df)} BBQ examples loaded\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZtsAmNAdJwr6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# CREATE GROUP IDENTIFIERS\n",
        "## Grouping BBQ databse with category and Question Index\n",
        "## Hashing the category and Question Index\n"
      ],
      "metadata": {
        "id": "X6bNZLpNJwr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîß CREATING GROUP IDENTIFIERS & VISUALIZING DISTRIBUTION\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "def create_group_identifier(row):\n",
        "    \"\"\"\n",
        "    Create unique group ID to keep paired/similar prompts together.\n",
        "    Returns both a readable string (for plots) and a hashed ID (for processing).\n",
        "    \"\"\"\n",
        "\n",
        "    group_str = f\"{row['category']}-{row['question_index']}\"\n",
        "\n",
        "    return group_str, hash(group_str) % 100000\n",
        "\n",
        "\n",
        "df[['group_name', 'group_id']] = df.apply(\n",
        "    lambda row: pd.Series(create_group_identifier(row)), axis=1\n",
        ")\n",
        "\n",
        "\n",
        "print(f\" Created group identifiers\")\n",
        "print(f\"   Total samples: {len(df):,}\")\n",
        "print(f\"   Unique groups: {df['group_id'].nunique():,}\")\n",
        "print(f\"   Avg samples per group: {len(df) / df['group_id'].nunique():.2f}\")\n",
        "\n",
        "group_sizes = df.groupby('group_name').size()\n",
        "print(f\"   Group size range: {group_sizes.min()} - {group_sizes.max()}\")\n",
        "print(f\"   Groups with >1 sample: {(group_sizes > 1).sum():,}\")\n",
        "\n",
        "\n",
        "# Set plot style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Create a figure with 3 subplots\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 18))\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "# --- PLOT 1: Distribution of Group Sizes (Histogram) ---\n",
        "# This shows if your groups are balanced (e.g., do most groups have 2 questions?)\n",
        "size_counts = group_sizes.value_counts().sort_index()\n",
        "sns.barplot(x=size_counts.index, y=size_counts.values, ax=axes[0], palette=\"viridis\")\n",
        "axes[0].set_title('Distribution of Group Sizes (How many items per group?)', fontsize=14)\n",
        "axes[0].set_xlabel('Number of Items in Group')\n",
        "axes[0].set_ylabel('Count of Groups')\n",
        "axes[0].bar_label(axes[0].containers[0])\n",
        "\n",
        "# --- PLOT 2: Top 20 Largest Groups by Name ---\n",
        "# This identifies specific groups that might be \"too big\" (Outliers)\n",
        "top_groups = group_sizes.sort_values(ascending=False).head(20)\n",
        "sns.barplot(x=top_groups.values, y=top_groups.index, ax=axes[1], palette=\"magma\")\n",
        "axes[1].set_title('Top 20 Largest Groups (Outliers)', fontsize=14)\n",
        "axes[1].set_xlabel('Number of Samples')\n",
        "axes[1].set_ylabel('Group Name')\n",
        "axes[1].bar_label(axes[1].containers[0])\n",
        "\n",
        "# --- PLOT 3: Number of Unique Groups per Category ---\n",
        "# This checks if one category dominates the dataset\n",
        "cat_counts = df.groupby('category')['group_id'].nunique().sort_values(ascending=False)\n",
        "sns.barplot(x=cat_counts.values, y=cat_counts.index, ax=axes[2], palette=\"coolwarm\")\n",
        "axes[2].set_title('Number of Unique Groups per Category', fontsize=14)\n",
        "axes[2].set_xlabel('Unique Group Count')\n",
        "axes[2].bar_label(axes[2].containers[0])\n",
        "\n",
        "print(\"\\nüìä Generating plots...\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "R5wGrzM9Jwr7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the LLM Base Model"
      ],
      "metadata": {
        "id": "d4XFNiN0Jwr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" üß† LOADING BASE MODEL & INSPECTING HIDDEN STREAMS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# 1. Load Tokenizer & Model\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model.eval()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2. EXTRACT ARCHITECTURE DETAILS\n",
        "# ------------------------------------------------------------------\n",
        "# Different models store layer counts in different config attributes\n",
        "model_config = base_model.config\n",
        "num_layers = getattr(model_config, \"num_hidden_layers\", None)\n",
        "if num_layers is None:\n",
        "    num_layers = getattr(model_config, \"n_layer\", None) # GPT style\n",
        "\n",
        "hidden_size = getattr(model_config, \"hidden_size\", None)\n",
        "if hidden_size is None:\n",
        "    hidden_size = getattr(model_config, \"n_embd\", \"Unknown\")\n",
        "\n",
        "num_heads = getattr(model_config, \"num_attention_heads\", getattr(model_config, \"n_head\", \"Unknown\"))\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3. VISUALIZE THE HIDDEN STATE STREAM\n",
        "# ------------------------------------------------------------------\n",
        "print(f\"‚úÖ Loaded Model: {config.base_model_name}\")\n",
        "print(f\"   ‚Ä¢ Model Type: {model_config.model_type}\")\n",
        "print(f\"   ‚Ä¢ Vocabulary: {model_config.vocab_size:,} tokens\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"üåä HIDDEN STATE STREAM STRUCTURE\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Visualizing the Data Flow\n",
        "print(f\"   [INPUT] (Batch, Seq_Len)\")\n",
        "print(f\"      ‚¨á\")\n",
        "print(f\"   [EMBEDDING] ‚ûú Transforms tokens to vector size {hidden_size}\")\n",
        "print(f\"      ‚¨á\")\n",
        "\n",
        "# The \"Stream\" - The stack of Transformer Blocks\n",
        "if num_layers:\n",
        "    # Draw the stack\n",
        "    print(f\"   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
        "    print(f\"   ‚ïë  HIDDEN LAYERS (The Stream)        ‚ïë\")\n",
        "    print(f\"   ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\")\n",
        "    print(f\"   ‚ïë  Layer  1 / {num_layers:<3} (Start)           ‚ïë\")\n",
        "    print(f\"   ‚ïë  Layer  2 / {num_layers:<3}                   ‚ïë\")\n",
        "    print(f\"   ‚ïë    ... (Identical Blocks) ...      ‚ïë\")\n",
        "    print(f\"   ‚ïë    ... (Attn + MLP + Norm)...      ‚ïë\")\n",
        "    print(f\"   ‚ïë  Layer {num_layers} / {num_layers:<3} (End)             ‚ïë\")\n",
        "    print(f\"   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
        "    print(f\"      ‚¨á (Stream Size: {hidden_size} dims, {num_heads} Attn Heads)\")\n",
        "else:\n",
        "    print(\"   [Unknown Layer Structure - could not detect num_hidden_layers]\")\n",
        "\n",
        "print(f\"   [OUTPUT HEAD] ‚ûú Projects {hidden_size} back to {model_config.vocab_size}\")\n",
        "print(f\"      ‚¨á\")\n",
        "print(f\"   [LOGITS] (Probabilities for next token)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "w16Dv_XRJwr7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Extract BBQ Activations"
      ],
      "metadata": {
        "id": "RkwxjaFSJwr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bbq_activations(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    merged_df: pd.DataFrame,\n",
        "    config: TrainingConfig,\n",
        "    layer_idx: int\n",
        ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Extract activations with STRICT labeling logic to ensure clean steering vectors.\n",
        "\n",
        "    Logic Update:\n",
        "    - Biased (0): Model selects the Stereotypical Target (target_loc).\n",
        "    - Unbiased (1): Model selects the Neutral/Unknown option (Dynamically found).\n",
        "    - Skip: Model selects the Counter-Stereotypical group or we can't find neutral option.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    activations = []\n",
        "    labels = []\n",
        "    group_ids = []\n",
        "\n",
        "    stats = {'biased': 0, 'unbiased': 0, 'skipped': 0, 'failed': 0}\n",
        "\n",
        "    # Ensure we have a group_id column\n",
        "    if 'group_id' not in merged_df.columns:\n",
        "        print(\"Generating group IDs...\")\n",
        "        merged_df['group_id'] = merged_df.apply(\n",
        "            lambda x: hash(f\"{x['category']}-{x['question_index']}\") % 100000, axis=1\n",
        "        )\n",
        "\n",
        "    # Pre-tokenization map for A, B, C\n",
        "    token_map = {\n",
        "        0: tokenizer.encode('A', add_special_tokens=False)[0],\n",
        "        1: tokenizer.encode('B', add_special_tokens=False)[0],\n",
        "        2: tokenizer.encode('C', add_special_tokens=False)[0]\n",
        "    }\n",
        "\n",
        "    print(f\"Extraction Layer {layer_idx} | Strict Mode: ON (Robust Neutral Detection)\")\n",
        "\n",
        "    # EXPANDED list of neutral keywords to catch all valid unbiased answers\n",
        "    neutral_keywords = [\n",
        "        \"unknown\",\n",
        "        \"can't be determined\",\n",
        "        \"cannot be determined\",\n",
        "        \"undetermined\",\n",
        "        \"not enough info\",\n",
        "        \"not enough information\",\n",
        "        \"not answerable\",\n",
        "        \"not specified\",\n",
        "        \"not stated\",\n",
        "        \"insufficient information\",\n",
        "        \"neither\",\n",
        "        \"none of the above\"\n",
        "    ]\n",
        "\n",
        "    for idx, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=f\"Layer {layer_idx}\"):\n",
        "        try:\n",
        "            context = row.get('context', '')\n",
        "            question = row.get('question', '')\n",
        "            ans0 = str(row.get('ans0', ''))\n",
        "            ans1 = str(row.get('ans1', ''))\n",
        "            ans2 = str(row.get('ans2', ''))\n",
        "            target_loc = int(row.get('target_loc', -1))\n",
        "            context_condition = row.get('context_condition', '')\n",
        "\n",
        "            #capture the failed records by filtering out target_loc and context_condition are empty or -1.\n",
        "            if target_loc == -1 or context_condition == '':\n",
        "                stats['failed'] += 1\n",
        "                continue\n",
        "\n",
        "            # ----------------------------------------------------------------\n",
        "            # 1. Identify the Neutral / Unknown Index dynamically (STRICT)\n",
        "            # ----------------------------------------------------------------\n",
        "            choices = [ans0, ans1, ans2]\n",
        "            unknown_idx = -1\n",
        "\n",
        "            for i, choice in enumerate(choices):\n",
        "                c_lower = choice.lower().strip()\n",
        "                # Check against the expanded list of neutral phrases\n",
        "                if any(kw in c_lower for kw in neutral_keywords):\n",
        "                    unknown_idx = i\n",
        "                    break\n",
        "\n",
        "            # STRICT RULE: If we cannot explicitly find the \"Neutral\" text,\n",
        "            # we DO NOT guess. We skip this sample to prevent label noise.\n",
        "            if unknown_idx == -1:\n",
        "                stats['skipped'] += 1\n",
        "                continue\n",
        "\n",
        "            # ----------------------------------------------------------------\n",
        "            # 2. Forward Pass\n",
        "            # ----------------------------------------------------------------\n",
        "            prompt = f\"{context} {question}\\nA. {ans0}\\nB. {ans1}\\nC. {ans2}\\nAnswer:\"\n",
        "\n",
        "            inputs = tokenizer(\n",
        "                prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                max_length=config.max_length,\n",
        "                truncation=True,\n",
        "                padding=True\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
        "\n",
        "            # Extract last token hidden state\n",
        "            hidden_states = outputs.hidden_states[layer_idx]\n",
        "            last_token_hidden = hidden_states[:, -1, :].cpu().numpy()[0]\n",
        "\n",
        "            # ----------------------------------------------------------------\n",
        "            # 3. Prediction & Strict Labeling\n",
        "            # ----------------------------------------------------------------\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            pred_probs = [probs[0, token_map[i]].item() for i in range(3)]\n",
        "            predicted_idx = np.argmax(pred_probs)\n",
        "\n",
        "            label = -1\n",
        "\n",
        "            if context_condition == 'ambig':\n",
        "                if predicted_idx == target_loc:\n",
        "                    # Model picked the stereotype -> BIASED\n",
        "                    label = config.LABEL_BIASED\n",
        "                    stats['biased'] += 1\n",
        "                elif predicted_idx == unknown_idx:\n",
        "                    # Model picked the neutral option -> UNBIASED\n",
        "                    label = config.LABEL_UNBIASED\n",
        "                    stats['unbiased'] += 1\n",
        "                else:\n",
        "                    # Model picked the counter-stereotypical group.\n",
        "                    stats['skipped'] += 1\n",
        "\n",
        "            elif context_condition == 'disambig':\n",
        "                # Use ground truth logic for disambiguated contexts\n",
        "                correct_label = int(row.get('label', -1))\n",
        "\n",
        "                if correct_label != -1:\n",
        "                    if predicted_idx == target_loc and predicted_idx != correct_label:\n",
        "                        # Stereotype is wrong, but model picked it -> BIASED\n",
        "                        label = config.LABEL_BIASED\n",
        "                        stats['biased'] += 1\n",
        "                    elif predicted_idx == correct_label:\n",
        "                        # Model picked correct answer -> UNBIASED\n",
        "                        label = config.LABEL_UNBIASED\n",
        "                        stats['unbiased'] += 1\n",
        "                    else:\n",
        "                        stats['skipped'] += 1\n",
        "                else:\n",
        "                    stats['skipped'] += 1\n",
        "\n",
        "            # 4. Save to buffer\n",
        "            if label != -1:\n",
        "                activations.append(last_token_hidden)\n",
        "                labels.append(label)\n",
        "                group_ids.append(row['group_id'])\n",
        "\n",
        "        except Exception as e:\n",
        "            stats['failed'] += 1\n",
        "            continue\n",
        "\n",
        "    print(f\"   Stats: Biased={stats['biased']}, Unbiased={stats['unbiased']}, Skipped={stats['skipped']}, Failed/Err={stats['failed']}\")\n",
        "\n",
        "    return np.array(activations), np.array(labels), np.array(group_ids)\n",
        "\n",
        "print(\"‚úÖ FairSteer-aligned extraction function (Strict Dynamic Neutral Detection) defined\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "5lLYjQ_yJwr7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Balance Dataset for training uses"
      ],
      "metadata": {
        "id": "9f9LYJY-Jwr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def visualize_pipeline_stats(X_raw, X_scaled, y_train, y_val, groups_train, groups_val):\n",
        "    \"\"\"Helper to verify data health\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # 1. Class Balance\n",
        "    sns.countplot(x=y_train, ax=axes[0], color='skyblue', label='Train')\n",
        "    axes[0].set_title(f\"Class Balance (Train: {len(y_train)})\")\n",
        "    axes[0].set_xticklabels(['Biased', 'Unbiased'])\n",
        "\n",
        "    # 2. Distribution Shift (First dimension as proxy)\n",
        "    # We use X_raw vs X_scaled. They MUST be the same length.\n",
        "    if len(X_raw) > 0 and len(X_scaled) > 0:\n",
        "        # Pick a random sample index valid for both\n",
        "        idx = np.random.randint(0, len(X_raw))\n",
        "\n",
        "        # Compare distribution of features for one sample\n",
        "        sns.kdeplot(X_raw[idx].flatten(), ax=axes[1], color='red', label='Raw (Bal)', fill=True, alpha=0.3)\n",
        "        sns.kdeplot(X_scaled[idx].flatten(), ax=axes[1], color='blue', label='Scaled', fill=True, alpha=0.3)\n",
        "        axes[1].set_title(\"Feature Distribution (Single Sample)\")\n",
        "        axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def prepare_data_pipeline(activations, labels, group_ids, config):\n",
        "    \"\"\"\n",
        "    Implements Dr. Raj's Pipeline:\n",
        "    1. Split by Group (prevent leakage)\n",
        "    2. Balance (downsample majority)\n",
        "    3. Standardize (Zero-mean, Unit-variance)\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"  üîß DATA PIPELINE EXECUTION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 1. Group-wise Split (Prevent Leakage)\n",
        "    # ---------------------------------------------------------\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=config.train_val_split, random_state=config.SEED)\n",
        "    train_idx, val_idx = next(gss.split(activations, labels, groups=group_ids))\n",
        "\n",
        "    X_train_raw, y_train_raw, g_train_raw = activations[train_idx], labels[train_idx], group_ids[train_idx]\n",
        "    X_val_raw, y_val_raw, g_val_raw = activations[val_idx], labels[val_idx], group_ids[val_idx]\n",
        "\n",
        "    # Overlap check\n",
        "    train_groups = set(g_train_raw)\n",
        "    val_groups = set(g_val_raw)\n",
        "    overlap = train_groups.intersection(val_groups)\n",
        "\n",
        "    print(f\"  Step 1: Split (Group-wise)\")\n",
        "    print(f\"     Train Samples: {len(X_train_raw):,}\")\n",
        "    print(f\"     Val Samples:   {len(X_val_raw):,}\")\n",
        "    if len(overlap) == 0:\n",
        "        print(f\"     ‚úÖ LEAKAGE CHECK PASSED: 0 overlapping groups.\")\n",
        "    else:\n",
        "        print(f\"     ‚ùå WARNING: {len(overlap)} GROUPS LEAKED!\")\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 2. Balance Data (Downsample majority class)\n",
        "    # ---------------------------------------------------------\n",
        "    def balance_subset(X, y, g):\n",
        "        X_biased = X[y == config.LABEL_BIASED]\n",
        "        X_unbiased = X[y == config.LABEL_UNBIASED]\n",
        "        g_biased = g[y == config.LABEL_BIASED]\n",
        "        g_unbiased = g[y == config.LABEL_UNBIASED]\n",
        "\n",
        "        n_samples = min(len(X_biased), len(X_unbiased))\n",
        "        if config.target_samples_per_class:\n",
        "            n_samples = min(n_samples, config.target_samples_per_class)\n",
        "\n",
        "        # Resample\n",
        "        X_b_res, g_b_res = resample(X_biased, g_biased, n_samples=n_samples, random_state=config.SEED, replace=False)\n",
        "        X_u_res, g_u_res = resample(X_unbiased, g_unbiased, n_samples=n_samples, random_state=config.SEED, replace=False)\n",
        "\n",
        "        X_bal = np.vstack([X_b_res, X_u_res])\n",
        "        y_bal = np.array([config.LABEL_BIASED]*n_samples + [config.LABEL_UNBIASED]*n_samples)\n",
        "        g_bal = np.concatenate([g_b_res, g_u_res])\n",
        "\n",
        "        # Shuffle\n",
        "        p = np.random.permutation(len(X_bal))\n",
        "        return X_bal[p], y_bal[p], g_bal[p]\n",
        "\n",
        "    X_train_bal, y_train_bal, g_train_bal = balance_subset(X_train_raw, y_train_raw, g_train_raw)\n",
        "    X_val_bal, y_val_bal, g_val_bal = balance_subset(X_val_raw, y_val_raw, g_val_raw)\n",
        "\n",
        "    print(f\"  Step 2: Balanced\")\n",
        "    print(f\"     Train: {len(X_train_bal):,} (Groups: {len(np.unique(g_train_bal)):,})\")\n",
        "    print(f\"     Val:   {len(X_val_bal):,} (Groups: {len(np.unique(g_val_bal)):,})\")\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3. Standardization (Critical for Linear Probe)\n",
        "    # ---------------------------------------------------------\n",
        "    # Convert to float32 to avoid 'inf' variance in float16\n",
        "    X_train_bal = X_train_bal.astype(np.float32)\n",
        "    X_val_bal = X_val_bal.astype(np.float32)\n",
        "\n",
        "    # Clean any existing NaNs/Infs\n",
        "    if not np.isfinite(X_train_bal).all():\n",
        "        print(\"     ‚ö†Ô∏è Warning: Found NaNs/Infs in activations. Replacing with 0.\")\n",
        "        X_train_bal = np.nan_to_num(X_train_bal)\n",
        "        X_val_bal = np.nan_to_num(X_val_bal)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_bal)\n",
        "    X_val_scaled = scaler.transform(X_val_bal)\n",
        "\n",
        "    print(f\"  Step 3: Standardized\")\n",
        "    print(f\"     Before Scaling -> Mean: {np.mean(X_train_bal):.4f}, Std: {np.std(X_train_bal):.4f}\")\n",
        "    print(f\"     After Scaling  -> Mean: {np.mean(X_train_scaled):.4f},  Std: {np.std(X_train_scaled):.4f}\")\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4. Visualize (Pass the BALANCED raw data)\n",
        "    # ---------------------------------------------------------\n",
        "    # We pass X_train_bal (not X_train_raw) so sizes match X_train_scaled\n",
        "    visualize_pipeline_stats(X_train_bal, X_train_scaled, y_train_bal, y_val_bal, g_train_bal, g_val_bal)\n",
        "\n",
        "    return X_train_scaled, y_train_bal, X_val_scaled, y_val_bal, scaler\n",
        "\n",
        "print(\"‚úÖ Data Pipeline defined (Split -> Balance -> Standardize) with Visualization Fix\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "RcD5NKnlJwr8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Extract and Balance for All Layers"
      ],
      "metadata": {
        "id": "nHaiddY4Jwr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" Extracting & Processing Data (Optimized Single-Pass with Visuals)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# Get absolute paths to avoid confusion\n",
        "cwd = os.getcwd()\n",
        "abs_save_dir = os.path.abspath(config.local_save_dir)\n",
        "cache_dir = os.path.join(abs_save_dir, \"cache_processed_layers\")\n",
        "\n",
        "print(f\"üìç Current Working Dir:  {cwd}\")\n",
        "print(f\"üìÇ Expected Cache Dir:   {cache_dir}\")\n",
        "\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "def get_cache_path(layer_idx):\n",
        "    return os.path.join(cache_dir, f\"layer_{layer_idx}_data.pkl\")\n",
        "\n",
        "\n",
        "missing_layers = []\n",
        "found_layers = []\n",
        "\n",
        "print(f\"\\nüîç Checking for {len(config.candidate_layers_range)} layer files...\")\n",
        "\n",
        "for l in config.candidate_layers_range:\n",
        "    fpath = get_cache_path(l)\n",
        "    if os.path.exists(fpath):\n",
        "        # Check if file is not empty (0 bytes)\n",
        "        if os.path.getsize(fpath) > 0:\n",
        "            found_layers.append(l)\n",
        "            # print(f\"   ‚úÖ Found Layer {l}\") # Optional verbose\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è Layer {l} found but is EMPTY (0 bytes). Will re-extract.\")\n",
        "            missing_layers.append(l)\n",
        "    else:\n",
        "        # print(f\"   ‚ùå Missing Layer {l}\") # Optional verbose\n",
        "        missing_layers.append(l)\n",
        "\n",
        "# Decision Logic\n",
        "all_layer_data = {}\n",
        "\n",
        "if len(missing_layers) == 0:\n",
        "    print(f\"\\n‚ö° CACHE COMPLETE! Loading data for {len(found_layers)} layers...\")\n",
        "    for layer_idx in tqdm(config.candidate_layers_range, desc=\"Loading Cache\"):\n",
        "        with open(get_cache_path(layer_idx), \"rb\") as f:\n",
        "            all_layer_data[layer_idx] = pickle.load(f)\n",
        "    print(\"‚úÖ All data loaded successfully. Skipping extraction.\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nüê¢ Cache incomplete ({len(missing_layers)} missing).\")\n",
        "    print(f\"   Missing Layers: {missing_layers}\")\n",
        "    print(\"   üöÄ Starting SINGLE-PASS extraction...\")\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # OPTIMIZED INFERENCE LOOP (Runs only if cache missing)\n",
        "    # -------------------------------------------------------\n",
        "\n",
        "    # Buffers\n",
        "    layer_buffers = {l: [] for l in config.candidate_layers_range}\n",
        "    labels_buffer = []\n",
        "    groups_buffer = []\n",
        "    stats = {'biased': 0, 'unbiased': 0, 'failed': 0}\n",
        "\n",
        "    # Prepare Data\n",
        "    extraction_df = bbq_merged_df.copy()\n",
        "    if 'group_id' not in extraction_df.columns:\n",
        "         extraction_df['group_id'] = extraction_df.apply(\n",
        "             lambda x: hash(f\"{x['category']}-{x['question_index']}\") % 100000, axis=1\n",
        "         )\n",
        "\n",
        "    base_model.eval()\n",
        "\n",
        "    # Live Progress Bar\n",
        "    pbar = tqdm(extraction_df.iterrows(), total=len(extraction_df), desc=\"Extracting\")\n",
        "\n",
        "    for idx, row in pbar:\n",
        "        try:\n",
        "            # Inputs\n",
        "            context = row.get('context', '')\n",
        "            question = row.get('question', '')\n",
        "            ans0, ans1, ans2 = row.get('ans0', ''), row.get('ans1', ''), row.get('ans2', '')\n",
        "            target_loc = int(row.get('target_loc', -1))\n",
        "            context_condition = row.get('context_condition', '')\n",
        "\n",
        "            if target_loc == -1 or context_condition == '':\n",
        "                stats['failed'] += 1\n",
        "                continue\n",
        "\n",
        "            prompt = f\"{context} {question}\\nA. {ans0}\\nB. {ans1}\\nC. {ans2}\\nAnswer:\"\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=config.max_length, truncation=True).to(device)\n",
        "\n",
        "            # Forward\n",
        "            with torch.no_grad():\n",
        "                outputs = base_model(**inputs, output_hidden_states=True, return_dict=True)\n",
        "\n",
        "            # Labeling\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            t_map = [tokenizer.encode(k, add_special_tokens=False)[0] for k in ['A', 'B', 'C']]\n",
        "            pred_probs = [probs[0, t].item() for t in t_map]\n",
        "            predicted_idx = np.argmax(pred_probs)\n",
        "\n",
        "            label = -1\n",
        "            if context_condition == 'ambig':\n",
        "                label = config.LABEL_BIASED if predicted_idx == target_loc else config.LABEL_UNBIASED\n",
        "            elif context_condition == 'disambig':\n",
        "                label = config.LABEL_BIASED if predicted_idx == 2 else config.LABEL_UNBIASED\n",
        "\n",
        "            # Store\n",
        "            if label != -1:\n",
        "                labels_buffer.append(label)\n",
        "                groups_buffer.append(row['group_id'])\n",
        "\n",
        "                if label == config.LABEL_BIASED: stats['biased'] += 1\n",
        "                else: stats['unbiased'] += 1\n",
        "\n",
        "                # Extract from ALL layers\n",
        "                for layer_idx in config.candidate_layers_range:\n",
        "                    hidden = outputs.hidden_states[layer_idx][:, -1, :].cpu().numpy()[0]\n",
        "                    layer_buffers[layer_idx].append(hidden)\n",
        "\n",
        "            if (stats['biased'] + stats['unbiased']) % 100 == 0:\n",
        "                pbar.set_postfix({'B': stats['biased'], 'U': stats['unbiased']})\n",
        "\n",
        "        except Exception as e:\n",
        "            stats['failed'] += 1\n",
        "            continue\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # PROCESSING & SAVING\n",
        "    # -------------------------------------------------------\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" üíæ PROCESSING & SAVING TO DISK\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    final_labels = np.array(labels_buffer)\n",
        "    final_groups = np.array(groups_buffer)\n",
        "\n",
        "    for layer_idx in config.candidate_layers_range:\n",
        "        print(f\"  > Processing Layer {layer_idx}...\")\n",
        "\n",
        "        final_acts = np.array(layer_buffers[layer_idx])\n",
        "\n",
        "        # Run Dr. Raj's Pipeline\n",
        "        X_train, y_train, X_val, y_val, scaler = prepare_data_pipeline(\n",
        "            final_acts, final_labels, final_groups, config\n",
        "        )\n",
        "\n",
        "        layer_data = {\n",
        "            'X_train': X_train, 'y_train': y_train,\n",
        "            'X_val': X_val, 'y_val': y_val,\n",
        "            'scaler': scaler\n",
        "        }\n",
        "\n",
        "        # Save\n",
        "        save_path = get_cache_path(layer_idx)\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            pickle.dump(layer_data, f)\n",
        "\n",
        "        all_layer_data[layer_idx] = layer_data\n",
        "        print(f\"    ‚úÖ Saved: {save_path}\")\n",
        "\n",
        "print(f\"\\n‚úÖ ALL SYSTEMS GO. Data Ready.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "I2BibwytJwr8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Training Function\n",
        "## Start trainig the BAD MODEL with the ready balanced dataset"
      ],
      "metadata": {
        "id": "srlcxJzYJwr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import (\n",
        "    balanced_accuracy_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_curve,\n",
        "    auc\n",
        ")\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VISUALIZATION HELPER FUNCTIONS\n",
        "# ============================================================================\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plots the evolution of Loss, AUC, and Accuracy over epochs.\"\"\"\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "    # Plot 1: Loss Curve\n",
        "    sns.lineplot(x=epochs, y=history['train_loss'], ax=axes[0], marker='o', label='Train Loss', color='red')\n",
        "    axes[0].set_title(\"Training Loss Evolution\")\n",
        "    axes[0].set_xlabel(\"Epoch\")\n",
        "    axes[0].set_ylabel(\"Loss\")\n",
        "\n",
        "    # Plot 2: Metrics Curve\n",
        "    sns.lineplot(x=epochs, y=history['val_bal_acc'], ax=axes[1], marker='o', label='Val Balanced Acc', color='blue')\n",
        "    sns.lineplot(x=epochs, y=history['val_auc'], ax=axes[1], marker='s', label='Val AUC', color='green')\n",
        "    axes[1].set_title(\"Validation Metrics Evolution\")\n",
        "    axes[1].set_xlabel(\"Epoch\")\n",
        "    axes[1].set_ylabel(\"Score\")\n",
        "    axes[1].set_ylim(0.4, 1.05)\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_final_evaluation(y_true, y_probs, y_preds):\n",
        "    \"\"\"Plots Confusion Matrix and ROC Curve for the best model.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Plot 1: Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_preds)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=False,\n",
        "                xticklabels=['Unbiased (0)', 'Biased (1)'],\n",
        "                yticklabels=['Unbiased (0)', 'Biased (1)'])\n",
        "    axes[0].set_title(\"Confusion Matrix (Best Model)\")\n",
        "    axes[0].set_xlabel(\"Predicted\")\n",
        "    axes[0].set_ylabel(\"Actual\")\n",
        "\n",
        "    # Plot 2: ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    axes[1].set_xlim([0.0, 1.0])\n",
        "    axes[1].set_ylim([0.0, 1.05])\n",
        "    axes[1].set_xlabel('False Positive Rate')\n",
        "    axes[1].set_ylabel('True Positive Rate')\n",
        "    axes[1].set_title('Receiver Operating Characteristic (ROC)')\n",
        "    axes[1].legend(loc=\"lower right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_bad_classifier(\n",
        "    X_train, y_train, X_val, y_val,\n",
        "    config,\n",
        "    layer_idx: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains a probe/classifier with comprehensive logging and visualization.\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(f\" üöÄ TRAINING BAD CLASSIFIER - LAYER {layer_idx}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. Setup Data\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
        "    X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_val_t = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "    val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    model = BADClassifier(\n",
        "    input_dim=X_train.shape[1],\n",
        "    dropout_rate=config.dropout_rate).to(device)\n",
        "\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "\n",
        "\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=3\n",
        "    )\n",
        "\n",
        "    # 3. Training Loop\n",
        "    best_metric = 0.0\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "    history = {'val_auc': [], 'val_bal_acc': [], 'train_loss': []}\n",
        "\n",
        "    print(f\"   Starting training on {device} for {config.num_epochs} epochs...\")\n",
        "    print(f\"   {'Epoch':<6} | {'Loss':<8} | {'Bal Acc':<8} | {'AUC':<8} | {'Status'}\")\n",
        "    print(\"-\" * 55)\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        # --- TRAIN ---\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(batch_X).squeeze(-1)\n",
        "            loss = criterion(logits, batch_y)\n",
        "            loss.backward()\n",
        "\n",
        "            if config.gradient_clip_norm > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # --- VALIDATE ---\n",
        "        model.eval()\n",
        "        val_probs = []\n",
        "        val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                logits = model(batch_X).squeeze(-1)\n",
        "                probs = torch.sigmoid(logits)\n",
        "                val_probs.extend(probs.cpu().numpy())\n",
        "                val_targets.extend(batch_y.cpu().numpy())\n",
        "\n",
        "        # --- METRICS ---\n",
        "        val_preds = [1 if p >= 0.5 else 0 for p in val_probs]\n",
        "        val_bal_acc = balanced_accuracy_score(val_targets, val_preds)\n",
        "\n",
        "        try:\n",
        "            val_auc = roc_auc_score(val_targets, val_probs)\n",
        "        except ValueError:\n",
        "            val_auc = 0.5\n",
        "\n",
        "        # Store history\n",
        "        history['val_bal_acc'].append(val_bal_acc)\n",
        "        history['val_auc'].append(val_auc)\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "\n",
        "        # Save Best\n",
        "        save_msg = \"\"\n",
        "        if val_bal_acc > best_metric:\n",
        "            best_metric = val_bal_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "            save_msg = \"‚≠ê New Best\"\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Print Status\n",
        "        print(f\"   {epoch+1:<6} | {avg_train_loss:.4f}   | {val_bal_acc:.4f}   | {val_auc:.4f}   | {save_msg}\")\n",
        "\n",
        "        # Scheduler & Early Stop\n",
        "        scheduler.step(val_bal_acc)\n",
        "\n",
        "        if patience_counter >= config.early_stopping_patience:\n",
        "            print(f\"\\nüõë Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    # 4. Final Evaluation & Visualization\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" üìä EVALUATING BEST MODEL\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    # Final predictions for reporting\n",
        "    model.eval()\n",
        "    final_probs = []\n",
        "    final_targets = []\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            batch_X = batch_X.to(device)\n",
        "            logits = model(batch_X).squeeze(-1)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            final_probs.extend(probs.cpu().numpy())\n",
        "            final_targets.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    final_preds = [1 if p >= 0.5 else 0 for p in final_probs]\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(final_targets, final_preds, target_names=['Biased', 'Unbiased']))\n",
        "\n",
        "    print(\"Generating Plots...\")\n",
        "    plot_training_history(history)\n",
        "    plot_final_evaluation(final_targets, final_probs, final_preds)\n",
        "\n",
        "    return model, best_metric, history\n",
        "\n",
        "print(\"‚úÖ Training function updated (Fixed PyTorch verbose error).\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "usPT6yzmJwr8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Train All Layers & Select Best"
      ],
      "metadata": {
        "id": "sTYeoe-TJwr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" üß† OPTIMIZATION: CLEARING VRAM BEFORE TRAINING\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# We have already extracted activations to CPU/Disk. We don't need the LLM on GPU anymore.\n",
        "if 'base_model' in globals():\n",
        "    print(\" üóëÔ∏è  Unloading Base Model to free GPU memory...\")\n",
        "    del base_model\n",
        "if 'tokenizer' in globals():\n",
        "    del tokenizer\n",
        "\n",
        "# 2. Force Garbage Collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Verify Memory\n",
        "if torch.cuda.is_available():\n",
        "    free_mem = torch.cuda.mem_get_info()[0] / 1024**3\n",
        "    print(f\" üíæ GPU Memory Free: {free_mem:.2f} GB (Should be high now)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Training BAD Classifiers for All Layers\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "layer_results = {}\n",
        "trained_models = {}\n",
        "trained_scalers = {}\n",
        "histories = {}\n",
        "\n",
        "best_layer = None\n",
        "best_score = 0.0\n",
        "\n",
        "# Iterate through candidate layers\n",
        "for layer_idx in config.candidate_layers_range:\n",
        "    print(f\"\\n{'='*60}\\n ‚öôÔ∏è  PROCESSING LAYER {layer_idx}\\n{'='*60}\")\n",
        "\n",
        "    # Retrieve Data\n",
        "    if layer_idx not in all_layer_data:\n",
        "        print(f\"‚ùå Error: Data for Layer {layer_idx} not found. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    layer_data = all_layer_data[layer_idx]\n",
        "\n",
        "    # Train\n",
        "    # Note: The training function moves small batches to GPU, computes gradients,\n",
        "    # and then releases them. This is very memory efficient.\n",
        "    try:\n",
        "        model, score, hist = train_bad_classifier(\n",
        "            layer_data['X_train'],\n",
        "            layer_data['y_train'],\n",
        "            layer_data['X_val'],\n",
        "            layer_data['y_val'],\n",
        "            config,\n",
        "            layer_idx\n",
        "        )\n",
        "\n",
        "        # Store Results\n",
        "        layer_results[layer_idx] = score\n",
        "        trained_models[layer_idx] = model.cpu() # Move model to CPU to save GPU for next iter\n",
        "        trained_scalers[layer_idx] = layer_data['scaler']\n",
        "        histories[layer_idx] = hist\n",
        "\n",
        "        # Track Best\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_layer = layer_idx\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        if \"out of memory\" in str(e):\n",
        "            print(f\"‚ùå OOM Error on Layer {layer_idx}. Skipping this layer.\")\n",
        "            torch.cuda.empty_cache()\n",
        "            continue\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "    # Aggressive Cleanup between layers\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Final Summary Table\n",
        "print(f\"\\n\\n{'='*80}\")\n",
        "print(f\" üèÜ LAYER SELECTION RESULTS (Metric: Balanced Accuracy)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "print(f\"{'Layer':<10} {'Bal Acc':<15} {'Improvement':<25} {'Status'}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for layer in sorted(layer_results.keys()):\n",
        "    acc = layer_results[layer]\n",
        "    improvement = (acc - 0.5) / 0.5 * 100\n",
        "\n",
        "    marker = \"\"\n",
        "    if layer == best_layer:\n",
        "        marker = \"‚≠ê‚≠ê WINNER ‚≠ê‚≠ê\"\n",
        "    elif acc > 0.75:\n",
        "        marker = \"‚úÖ Good Candidate\"\n",
        "\n",
        "    print(f\"{layer:<10} {acc:<15.4f} {f'+{improvement:.1f}%':<25} {marker}\")\n",
        "\n",
        "if best_layer is not None:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\" Final Decision: Selected Layer {best_layer}\")\n",
        "    print(f\" Best Balanced Accuracy: {best_score:.4f}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Move best model back to GPU for saving/evaluation if needed\n",
        "    trained_models[best_layer] = trained_models[best_layer].to(device)\n",
        "else:\n",
        "    print(\"\\n‚ùå Training failed for all layers.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "II5okekPJwr9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Visualize Results"
      ],
      "metadata": {
        "id": "JeBCzkAhJwr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\" üìä VISUALIZING RESULTS FOR BEST LAYER: {best_layer}\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "history = histories[best_layer]\n",
        "epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "# 2. Setup the dashboard\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "plt.suptitle(f\"Training Dynamics - Layer {best_layer} (Best Model)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "# Panel 1: Training Optimization (Loss)\n",
        "# -------------------------------------------------------\n",
        "loss_data = history['train_loss']\n",
        "ax1.plot(epochs, loss_data, 'b-', alpha=0.4, label='Raw Batch Loss')\n",
        "\n",
        "# Add a smoothed trend line if we have enough epochs\n",
        "if len(loss_data) > 5:\n",
        "    window = 5\n",
        "    smoothed = np.convolve(loss_data, np.ones(window)/window, mode='valid')\n",
        "    ax1.plot(range(window//2 + 1, len(smoothed) + window//2 + 1), smoothed, 'b-', linewidth=2, label='Smoothed Trend')\n",
        "\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('BCE Loss', fontsize=12)\n",
        "ax1.set_title('Optimization (Did it converge?)', fontsize=14)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Panel 2: Generalization (Metrics)\n",
        "# -------------------------------------------------------\n",
        "# We plot Balanced Acc vs AUC to check for threshold issues\n",
        "ax2.plot(epochs, history['val_bal_acc'], 'g-', linewidth=2, label='Balanced Acc (Decision)')\n",
        "ax2.plot(epochs, history['val_auc'], 'purple', linestyle='--', linewidth=2, label='AUC (Separability)')\n",
        "\n",
        "# Reference lines\n",
        "ax2.axhline(y=0.5, color='gray', linestyle=':', label='Random Baseline (0.5)')\n",
        "ax2.axhline(y=best_score, color='red', linestyle='--', alpha=0.5, label=f'Best: {best_score:.4f}')\n",
        "\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Score (0.0 - 1.0)', fontsize=12)\n",
        "ax2.set_title('Validation Performance', fontsize=14)\n",
        "ax2.set_ylim(0.4, 1.0) # Zoom in on relevant range\n",
        "ax2.legend(loc='lower right')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{config.local_save_dir}/training_dashboard.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\" Saved analysis to: {config.local_save_dir}/training_dashboard.png\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "XbM_DJq1Jwr9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Save Model"
      ],
      "metadata": {
        "id": "aAY3fXT8Jwr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" Saving Model & Assets\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "os.makedirs(config.local_save_dir, exist_ok=True)\n",
        "\n",
        "# 1. Save PyTorch Model\n",
        "torch.save(trained_models[best_layer].state_dict(), f\"{config.local_save_dir}/pytorch_model.bin\")\n",
        "print(f\" Saved: pytorch_model.bin\")\n",
        "\n",
        "# 2. Save Scaler\n",
        "# The inference pipeline must load this and apply .transform() before the model\n",
        "with open(f\"{config.local_save_dir}/scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(trained_scalers[best_layer], f)\n",
        "print(f\" Saved: scaler.pkl (StandardScaler)\")\n",
        "\n",
        "# 3. Save Config\n",
        "model_config = {\n",
        "    'input_dim': trained_models[best_layer].input_dim,\n",
        "    'layer_idx': best_layer,\n",
        "    'base_model': config.base_model_name,\n",
        "    'best_val_bal_acc': float(best_score),\n",
        "    'training_method': 'GroupSplit + Standardized + Balanced',\n",
        "    'training_date': datetime.now().isoformat()\n",
        "}\n",
        "with open(f\"{config.local_save_dir}/config.json\", 'w') as f:\n",
        "    json.dump(model_config, f, indent=2)\n",
        "print(f\" Saved: config.json\")\n",
        "\n",
        "print(f\"\\n All assets ready in {config.local_save_dir}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ITUjZKYjJwr9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Final Summary"
      ],
      "metadata": {
        "id": "5GtLcPcnJwr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\" TRAINING COMPLETE (IMPROVED & BALANCED)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Calculate total samples from the best layer's data\n",
        "best_layer_data = all_layer_data[best_layer]\n",
        "total_samples = len(best_layer_data['y_train']) + len(best_layer_data['y_val'])\n",
        "\n",
        "print(\" Final Results:\")\n",
        "print(f\"   Best Layer:       {best_layer}\")\n",
        "print(f\"   Best Bal Acc:     {best_score:.4f}\")\n",
        "print(f\"   Baseline:         0.5000 (50% random)\")\n",
        "print(f\"   Improvement:      {(best_score - 0.5) / 0.5 * 100:+.1f}% over baseline\")\n",
        "print(f\"\")\n",
        "print(f\"   Total Samples:    {total_samples:,} (Train + Val)\")\n",
        "print(f\"   Class Split:      50% BIASED, 50% UNBIASED (Perfectly Balanced)\")\n",
        "print(f\"   Pipeline:         Group Split -> Standardization -> Linear Probe\")\n",
        "print(f\"\")\n",
        "print(f\"   Save Location:    {config.local_save_dir}\")\n",
        "print(f\"\")\n",
        "\n",
        "# Comparison with previous attempt\n",
        "print(\" Comparison with Previous Attempts:\")\n",
        "print(f\"   Previous (Raw):   66.88% (Likely overfitting on duplicates)\")\n",
        "print(f\"   Current (Bal):    {best_score:.2%} (Robust, Group-split, Standardized)\")\n",
        "\n",
        "# Success Logic\n",
        "if best_score >= 0.80:\n",
        "    print(f\"\\n üöÄ EXCELLENT! Model is highly discriminative. FairSteer will work well.\")\n",
        "elif best_score >= 0.75:\n",
        "    print(f\"\\n ‚úÖ SUCCESS! Model is well-trained and ready for deployment.\")\n",
        "elif best_score >= 0.70:\n",
        "    print(f\"\\n ‚ö†Ô∏è ACCEPTABLE. Model is usable, but steering might be weak.\")\n",
        "else:\n",
        "    print(f\"\\n ‚ùå POOR. Consider increasing 'candidate_layers_range' or checking data.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "EhRstD28Jwr9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" üõ†Ô∏è FIXING MISSING HISTORY FILE\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Define the path\n",
        "history_path = f\"{config.local_save_dir}/training_history.json\"\n",
        "\n",
        "# Check if we have the data in memory\n",
        "if 'histories' in globals() and best_layer in histories:\n",
        "    print(f\" Found training history for Layer {best_layer} in memory.\")\n",
        "\n",
        "    # Helper to convert numpy values (which JSON hates) to standard floats\n",
        "    def clean_for_json(d):\n",
        "        new_d = {}\n",
        "        for k, v in d.items():\n",
        "            if isinstance(v, list):\n",
        "                new_d[k] = [float(x) for x in v]\n",
        "            elif isinstance(v, (np.ndarray, np.generic)):\n",
        "                new_d[k] = v.tolist()\n",
        "            else:\n",
        "                new_d[k] = v\n",
        "        return new_d\n",
        "\n",
        "    # Save it\n",
        "    try:\n",
        "        data_to_save = clean_for_json(histories[best_layer])\n",
        "        with open(history_path, 'w') as f:\n",
        "            json.dump(data_to_save, f, indent=2)\n",
        "        print(f\" ‚úÖ Success! Created: {history_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå Error saving JSON: {e}\")\n",
        "else:\n",
        "    # Fallback: Create a placeholder if memory was wiped\n",
        "    print(\" ‚ö†Ô∏è History variables not found in memory (did runtime restart?).\")\n",
        "    print(\"    Creating a placeholder file so upload succeeds.\")\n",
        "    dummy_data = {\n",
        "        \"status\": \"History data lost during session\",\n",
        "        \"layer\": best_layer,\n",
        "        \"final_accuracy\": float(best_score)\n",
        "    }\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(dummy_data, f, indent=2)\n",
        "    print(f\" ‚úÖ Created placeholder: {history_path}\")\n",
        "\n",
        "print(\"\\nüëâ Now re-run the 'DEPLOYING TO HUGGINGFACE' cell.\")"
      ],
      "metadata": {
        "id": "qTZTR1cabW1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Trained Model to HuggingFace with SafeTensors"
      ],
      "metadata": {
        "id": "DS1e7W9WJwr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy Trained Model to HuggingFace (Safetensors Version)\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import json\n",
        "import torch\n",
        "from huggingface_hub import HfApi, create_repo, login\n",
        "from safetensors.torch import save_file  # Required for conversion\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" üöÄ ROBUST DEPLOYMENT TO HUGGINGFACE (Safetensors)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# --- 1. CONFIGURATION & AUTH ---\n",
        "REPO_ID = config.hf_repo_name\n",
        "TARGET_FOLDER_NAME = \"bad_model_fairsteer_v2\"\n",
        "\n",
        "print(\"Step 1: Authentication\")\n",
        "hf_token = os.environ.get('HF_TOKEN', None)\n",
        "if not hf_token:\n",
        "    from getpass import getpass\n",
        "    print(\"  HF_TOKEN not found in environment variables\")\n",
        "    hf_token = getpass(\"Enter HuggingFace Token: \")\n",
        "\n",
        "try:\n",
        "    login(token=hf_token)\n",
        "    print(\"  ‚úÖ Authenticated\")\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ùå Failed: {e}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "print(\"\\nStep 2: Locating Model Files\")\n",
        "\n",
        "possible_paths = [\n",
        "    config.local_save_dir,\n",
        "    f\"./{TARGET_FOLDER_NAME}\",\n",
        "    f\"/kaggle/working/{TARGET_FOLDER_NAME}\",\n",
        "    f\"/content/{TARGET_FOLDER_NAME}\",\n",
        "    f\"../{TARGET_FOLDER_NAME}\"\n",
        "]\n",
        "\n",
        "SOURCE_DIR = None\n",
        "# We look for pytorch_model.bin in source, but we will convert it later\n",
        "required_files = [\"pytorch_model.bin\", \"config.json\", \"scaler.pkl\"]\n",
        "\n",
        "for path in possible_paths:\n",
        "    clean_path = os.path.abspath(path)\n",
        "    if os.path.exists(clean_path):\n",
        "        files_in_dir = os.listdir(clean_path)\n",
        "        if all(f in files_in_dir for f in required_files):\n",
        "            SOURCE_DIR = clean_path\n",
        "            print(f\"  ‚úÖ FOUND VALID MODEL AT: {SOURCE_DIR}\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"  ‚ö†Ô∏è  Found folder at {clean_path}, but it is missing files.\")\n",
        "\n",
        "if not SOURCE_DIR:\n",
        "    raise FileNotFoundError(\"Model files missing. Please check the Files sidebar.\")\n",
        "\n",
        "# --- 3. PREPARE UPLOAD ---\n",
        "print(\"\\nStep 3: Staging & Converting Files\")\n",
        "hf_upload_dir = tempfile.mkdtemp(prefix=\"bad_classifier_upload_\")\n",
        "print(f\"  Temp Staging Area: {hf_upload_dir}\")\n",
        "\n",
        "# We define what to take from source, and how to handle it\n",
        "files_to_process = [\n",
        "    \"pytorch_model.bin\", # Will be converted\n",
        "    \"config.json\",\n",
        "    \"scaler.pkl\",\n",
        "    \"training_history.json\",\n",
        "    \"training_dashboard.png\"\n",
        "]\n",
        "\n",
        "upload_manifest = []\n",
        "\n",
        "for filename in files_to_process:\n",
        "    src = os.path.join(SOURCE_DIR, filename)\n",
        "\n",
        "    if not os.path.exists(src):\n",
        "        print(f\"  ‚ö†Ô∏è Warning: {filename} not found (skipping)\")\n",
        "        continue\n",
        "\n",
        "    # SPECIAL HANDLING: Convert PyTorch Bin to Safetensors\n",
        "    if filename == \"pytorch_model.bin\":\n",
        "        dst = os.path.join(hf_upload_dir, \"model.safetensors\")\n",
        "        print(f\"  üîÑ Converting {filename} -> model.safetensors...\")\n",
        "        try:\n",
        "            # Load weights from pickle\n",
        "            state_dict = torch.load(src, map_location=\"cpu\")\n",
        "            # Save as safetensors\n",
        "            save_file(state_dict, dst)\n",
        "            size_mb = os.path.getsize(dst) / (1024 * 1024)\n",
        "            print(f\"  - Staged: model.safetensors ({size_mb:.2f} MB)\")\n",
        "            upload_manifest.append(\"model.safetensors\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Conversion Failed: {e}\")\n",
        "            raise e\n",
        "    else:\n",
        "        # Standard Copy\n",
        "        dst = os.path.join(hf_upload_dir, filename)\n",
        "        shutil.copy(src, dst)\n",
        "        size_mb = os.path.getsize(dst) / (1024 * 1024)\n",
        "        print(f\"  - Staged: {filename:<25} ({size_mb:.2f} MB)\")\n",
        "        upload_manifest.append(filename)\n",
        "\n",
        "# Create README.md\n",
        "readme_content = f\"\"\"---\n",
        "license: apache-2.0\n",
        "tags:\n",
        "- fairsteer\n",
        "- bias-detection\n",
        "- tinyllama\n",
        "- safetensors\n",
        "library_name: safetensors\n",
        "pipeline_tag: text-classification\n",
        "---\n",
        "\n",
        "# BAD Classifier for FairSteer\n",
        "\n",
        "Biased Activation Detection (BAD) classifier for TinyLlama-1.1B.\n",
        "\n",
        "## Artifacts\n",
        "- **Model**: `model.safetensors` (SafeTensors format)\n",
        "- **Scaler**: `scaler.pkl` (StandardScaler)\n",
        "- **Config**: `config.json`\n",
        "\n",
        "## Stats\n",
        "- **Balanced Accuracy**: {best_score:.2%}\n",
        "- **Best Layer**: {best_layer}\n",
        "- **Training Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
        "\"\"\"\n",
        "with open(f\"{hf_upload_dir}/README.md\", \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "upload_manifest.append(\"README.md\")\n",
        "\n",
        "# --- 4. UPLOAD ---\n",
        "print(\"\\nStep 4: Uploading to HuggingFace\")\n",
        "api = HfApi()\n",
        "\n",
        "try:\n",
        "    create_repo(repo_id=REPO_ID, token=hf_token, private=config.hf_private, repo_type=\"model\", exist_ok=True)\n",
        "\n",
        "    print(f\"  üöÄ Uploading {len(upload_manifest)} files to {REPO_ID}...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=hf_upload_dir,\n",
        "        repo_id=REPO_ID,\n",
        "        repo_type=\"model\",\n",
        "        token=hf_token,\n",
        "        commit_message=f\"Upload trained model (Safetensors) Acc: {best_score:.2%}\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ DEPLOYMENT SUCCESSFUL!\")\n",
        "    print(f\"üîó URL: https://huggingface.co/{REPO_ID}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Upload failed: {e}\")\n",
        "finally:\n",
        "    shutil.rmtree(hf_upload_dir)\n",
        "    print(\"  (Temp files cleaned up)\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ewAAHim6Jwr9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Test After Deployment"
      ],
      "metadata": {
        "id": "xoFlArrBJwr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick Test After Deployment\n",
        "print(\"=\"*80)\n",
        "print(\" QUICK TEST: Loading from HuggingFace (Safetensors)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "import pickle\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "\n",
        "try:\n",
        "    repo_id = config.hf_repo_name\n",
        "    print(f\"Target Repo: {repo_id}\")\n",
        "\n",
        "    # 1. Download Model (Safetensors)\n",
        "    print(\"Downloading model weights...\")\n",
        "    model_path = hf_hub_download(repo_id=repo_id, filename=\"model.safetensors\")\n",
        "\n",
        "    # 2. Download Config\n",
        "    print(\"Downloading config...\")\n",
        "    config_path = hf_hub_download(repo_id=repo_id, filename=\"config.json\")\n",
        "\n",
        "    # 3. Download Scaler\n",
        "    print(\"Downloading scaler...\")\n",
        "    scaler_path = hf_hub_download(repo_id=repo_id, filename=\"scaler.pkl\")\n",
        "\n",
        "    # 4. Validation checks\n",
        "    # Check Config\n",
        "    with open(config_path, 'r') as f:\n",
        "        uploaded_config = json.load(f)\n",
        "\n",
        "    # Check Scaler\n",
        "    with open(scaler_path, 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "\n",
        "    print(\"\\n‚úÖ INTEGRITY CHECKS PASSED!\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"1. Model Config:\")\n",
        "    print(f\"   - Layer Index: {uploaded_config.get('layer_idx', 'Unknown')}\")\n",
        "    print(f\"   - Input Dim:   {uploaded_config.get('input_dim', 'Unknown')}\")\n",
        "\n",
        "    # Check if safetensors file actually exists locally\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"2. Weights File:\")\n",
        "        print(f\"   - Location: {model_path}\")\n",
        "        print(f\"   - Size: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
        "\n",
        "    print(f\"3. Scaler Properties:\")\n",
        "    print(f\"   - Mean size:   {scaler.mean_.shape}\")\n",
        "\n",
        "    print(f\"\\nüéâ Model is publicly accessible and fully functional!\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå TEST FAILED: {e}\")\n",
        "    print(\"Possible reasons:\")\n",
        "    print(\" 1. The upload hasn't finished processing yet.\")\n",
        "    print(\" 2. You looked for 'pytorch_model.bin' but we uploaded 'model.safetensors'.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "WY_AFCWtJwr9"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}